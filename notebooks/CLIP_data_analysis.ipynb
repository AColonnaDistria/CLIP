{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2HyyJvOihuz",
        "outputId": "dfe03f07-ac2f-4336-cb77-9e9faff9b363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ9hWgwoisKB",
        "outputId": "cfa55111-b702-4604-ed13-ca6229770457"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive'\n",
            "/content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "colab_file_dir= \"MyDrive/Colab Notebooks/ML_FDS/\" # where clip_helpers.py is for me\n",
        "sys.path.append(colab_file_dir)"
      ],
      "metadata": {
        "id": "_34tLKCziwgd"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to python \"/content/gdrive/My Drive/Colab Notebooks/ML_FDS/CLIP_training_v2.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17-st08Kj4pA",
        "outputId": "889787e9-d6a1-4306-e997-e4d46508613b"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/gdrive/My Drive/Colab Notebooks/ML_FDS/CLIP_training_v2.ipynb to python\n",
            "[NbConvertApp] Writing 24168 bytes to /content/gdrive/My Drive/Colab Notebooks/ML_FDS/CLIP_training_v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks/ML_FDS/\")\n",
        "\n",
        "from CLIP_training_v2 import MaskedMean, ClipLossLayer, L2Normalize, SmallBERT"
      ],
      "metadata": {
        "id": "WDJ83rYzj8HS"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "id": "lU2VL1T8yJW8"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import zipfile\n",
        "import requests\n",
        "import io\n",
        "import math\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "import csv\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.utils import register_keras_serializable\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from tensorflow.keras.layers import Dropout, Rescaling\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# On n'utilise pas le GPU ici\n",
        "#AUTOTUNE = tf.data.AUTOTUNE\n"
      ],
      "metadata": {
        "id": "OtlxDCnSiwr3"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_params(\n",
        "        dataset_dir=\"./flickr_long_subset\",\n",
        "        model_dir=\"./models_forclip\",\n",
        "        figures_dir=\"figures\") -> dict:\n",
        "\n",
        "    # returns a dictionary with all the parameters\n",
        "    # parameters can be modified\n",
        "    train_dir = os.path.join(dataset_dir, \"train_data\")\n",
        "    val_dir = os.path.join(dataset_dir, \"val_data\")\n",
        "    test_dir = os.path.join(dataset_dir, \"test_data\")\n",
        "\n",
        "    train_image_dir = os.path.join(train_dir, \"images\")\n",
        "    train_captions_dir = os.path.join(train_dir, \"captions\")\n",
        "    train_captions_csv_path = os.path.join(train_dir, \"captions.csv\")\n",
        "\n",
        "    val_image_dir = os.path.join(val_dir, \"images\")\n",
        "    val_captions_dir = os.path.join(val_dir, \"captions\")\n",
        "    val_captions_csv_path = os.path.join(val_dir, \"captions.csv\")\n",
        "\n",
        "    test_image_dir = os.path.join(test_dir, \"images\")\n",
        "    test_captions_dir = os.path.join(test_dir, \"captions\")\n",
        "    test_captions_csv_path = os.path.join(test_dir, \"captions.csv\")\n",
        "\n",
        "    # token form train dataset\n",
        "    vocab_path = os.path.join(dataset_dir, \"vocab.txt\")\n",
        "\n",
        "    image_size = (224, 224)\n",
        "\n",
        "    param_dict = {\n",
        "        # directories for data and model weights\n",
        "\n",
        "\n",
        "        \"model_dir\": model_dir,\n",
        "        \"dataset_dir\": dataset_dir,\n",
        "        \"figures_dir\": figures_dir,\n",
        "        \"train_dir\": train_dir,\n",
        "        \"train_image_dir\": train_image_dir,\n",
        "        \"train_captions_dir\": train_captions_dir,\n",
        "        \"train_captions_csv_path\": train_captions_csv_path,\n",
        "\n",
        "        \"save_model_with_architecture\": True,\n",
        "\n",
        "        \"val_dir\": val_dir,\n",
        "        \"val_image_dir\": val_image_dir,\n",
        "        \"val_captions_dir\": val_captions_dir,\n",
        "        \"val_captions_csv_path\": val_captions_csv_path,\n",
        "\n",
        "        \"test_dir\": test_dir,\n",
        "        \"test_image_dir\": test_image_dir,\n",
        "        \"test_captions_dir\": test_captions_dir,\n",
        "        \"test_captions_csv_path\": test_captions_csv_path,\n",
        "\n",
        "        \"vocab_path\": vocab_path,\n",
        "\n",
        "        # model training parameters\n",
        "        # Attention respecter bien l'ordre alphabétique des classes pour\n",
        "        # le générateur\n",
        "        \"class_names\": ['ball', 'bike', 'dog', 'water'],\n",
        "        # class encoding dict\n",
        "        \"class_dict\": {\n",
        "            \"ball\": 0,\n",
        "            \"bike\": 1,\n",
        "            \"dog\": 2,\n",
        "            \"water\": 3\n",
        "        },\n",
        "        # Pour les images\n",
        "        \"image_size\": image_size,\n",
        "        \"image_shape\": image_size + (3,),\n",
        "\n",
        "\n",
        "        # Pour les textes\n",
        "        \"sequence_length\": 32,\n",
        "        \"vocab_size\": 10000,\n",
        "        \"num_heads\": 4,\n",
        "        \"ff_dim\": 128,\n",
        "        \"num_layers\": 2,\n",
        "        \"nb_image_filters\": 32,\n",
        "        \"pad_sequence\": True,\n",
        "\n",
        "        # Pour les images et les textes dans le modèle CLIP\n",
        "        \"embed_dim\": 128,\n",
        "        \"learning_rate\": 2e-4,\n",
        "        \"data_augmentation\": True,\n",
        "\n",
        "        # pour le training:\n",
        "        \"patience\": 5,\n",
        "        \"batch_size\": 64,\n",
        "        \"nb_epochs\": 15,\n",
        "    }\n",
        "\n",
        "    return param_dict\n"
      ],
      "metadata": {
        "id": "J7vjY14Ann4Z"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your directories here\n",
        "\n",
        "data_analysis_dir = \"My Drive/Colab Notebooks/ML_FDS/data_analysis\"\n",
        "model_dir = \"My Drive/Colab Notebooks/ML_FDS/models_forclip\"\n",
        "dataset_dir = \"My Drive/Colab Notebooks/ML_FDS/flickr_long_subset\"\n",
        "figure_dir = 'My Drive/Colab Notebooks/ML_FDS/figures/'\n",
        "param_dict = get_default_params(\n",
        "    dataset_dir=dataset_dir,\n",
        "    model_dir=model_dir,\n",
        "    figures_dir=figure_dir\n",
        ")"
      ],
      "metadata": {
        "id": "x0qTJSgGjAuS"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingExtractor:\n",
        "  def __init__(self,\n",
        "               model,\n",
        "               model_name,\n",
        "               data_directory,\n",
        "               vocab_size,\n",
        "               vocab_path,\n",
        "               output_sequence_length,\n",
        "               dataset_name = \"test\"):\n",
        "      self.model = model\n",
        "      self.model_name = model_name\n",
        "\n",
        "      image_input = model.inputs[0]\n",
        "      image_output = model.get_layer(\"image_latent_vector\").output\n",
        "\n",
        "      self.directory = data_directory\n",
        "      self.dataset_name = dataset_name\n",
        "\n",
        "      # Creation of Image Encoder\n",
        "      self.image_encoder = tf.keras.Model(\n",
        "          inputs=image_input,\n",
        "          outputs=image_output,\n",
        "          name=\"image_encoder\"\n",
        "      )\n",
        "\n",
        "      self.tokenizer = TextVectorization(\n",
        "          max_tokens=vocab_size,\n",
        "          standardize='lower_and_strip_punctuation',\n",
        "          split='whitespace',\n",
        "          vocabulary=vocab_path,\n",
        "          output_sequence_length=output_sequence_length,\n",
        "          output_mode=\"int\"  # save 0 for pad tokens\n",
        "      )\n",
        "\n",
        "      text_input = model.inputs[1]\n",
        "      text_output = model.get_layer(\"text_latent_vector\").output\n",
        "\n",
        "      self.text_encoder = tf.keras.Model(\n",
        "          inputs=text_input,\n",
        "          outputs=text_output,\n",
        "          name=\"text_encoder\"\n",
        "      )\n",
        "\n",
        "  def compute_embeddings(self):\n",
        "      # Image embeddings\n",
        "      captions_path = os.path.join(self.directory, \"captions.csv\")\n",
        "      df = pd.read_csv(captions_path)\n",
        "\n",
        "      image_paths = [str(Path(self.directory) / p) for p in df[\"image_path\"]]\n",
        "\n",
        "      # Compute Image embeddings\n",
        "      image_embeddings = []\n",
        "      for i in range(0, len(image_paths), 32):\n",
        "          batch = image_paths[i:i+32]\n",
        "          imgs = np.array([img_to_array(load_img(p, target_size=(224, 224)))/255. for p in batch])\n",
        "          image_embeddings.append(self.image_encoder.predict(imgs, verbose=0))\n",
        "\n",
        "      self.image_embeddings = np.vstack(image_embeddings)\n",
        "\n",
        "      # Text embeddings\n",
        "      captions = df[\"caption\"].fillna(\"\").tolist()\n",
        "\n",
        "      text_embeddings = []\n",
        "      for i in range(0, len(captions), 32):\n",
        "          batch = captions[i:i+32]\n",
        "          tokens = self.tokenizer(batch)\n",
        "          text_embeddings.append(self.text_encoder.predict(tokens, verbose=0))\n",
        "\n",
        "      self.text_embeddings = np.vstack(text_embeddings)\n",
        "\n",
        "  def get_embeddings(self):\n",
        "      return self.image_embeddings, self.text_embeddings"
      ],
      "metadata": {
        "id": "9hWD35z_zytl"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingAnalyzer:\n",
        "  def __init__(self,\n",
        "               image_embeddings, text_embeddings,\n",
        "               model_name = \"MODEL\",\n",
        "               dataset_name = \"test\",\n",
        "               data_analysis_dir = \"./data_analysis\"):\n",
        "      self.image_embeddings = image_embeddings / np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
        "      self.text_embeddings = text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "      self.model_name = model_name\n",
        "      self.dataset_name = dataset_name\n",
        "      self.data_analysis_dir = data_analysis_dir\n",
        "\n",
        "      self.df_embeddings_2d = None\n",
        "      self.df_stats = None\n",
        "      self.df_data_cos_sim = None\n",
        "\n",
        "  def compute_all(self):\n",
        "      self.compute_embeddings_stats()\n",
        "      self.compute_embeddings_cos_sim()\n",
        "      self.compute_pca_2d()\n",
        "\n",
        "  def compute_embeddings_stats(self):\n",
        "      mean_image_vector = self.image_embeddings.mean(axis=0)\n",
        "      max_image_vector = self.image_embeddings.max(axis=0)\n",
        "      min_image_vector = self.image_embeddings.min(axis=0)\n",
        "      std_image_vector = self.image_embeddings.std(axis=0)\n",
        "\n",
        "      mean_text_vector = self.text_embeddings.mean(axis=0)\n",
        "      max_text_vector = self.text_embeddings.max(axis=0)\n",
        "      min_text_vector = self.text_embeddings.min(axis=0)\n",
        "      std_text_vector = self.text_embeddings.std(axis=0)\n",
        "\n",
        "      stats = {\n",
        "          \"mean_image_vector\": mean_image_vector,\n",
        "          \"min_image_vector\": min_image_vector,\n",
        "          \"max_image_vector\": max_image_vector,\n",
        "          \"std_image_vector\": std_image_vector,\n",
        "\n",
        "          \"mean_text_vector\": mean_text_vector,\n",
        "          \"min_text_vector\": min_text_vector,\n",
        "          \"max_text_vector\": max_text_vector,\n",
        "          \"std_text_vector\": std_text_vector,\n",
        "      }\n",
        "\n",
        "      self.df_stats = pd.DataFrame(stats)\n",
        "\n",
        "  def compute_embeddings_cos_sim(self):\n",
        "      cos_sim = []\n",
        "\n",
        "      for i in range(len(self.image_embeddings)):\n",
        "          image_vector = self.image_embeddings[i]\n",
        "          text_vector = self.text_embeddings[i]\n",
        "\n",
        "          cos_sim.append(np.dot(image_vector, text_vector))\n",
        "\n",
        "      data_cos_sim = {\n",
        "          \"cos_sim\": cos_sim\n",
        "      }\n",
        "\n",
        "      self.df_data_cos_sim = pd.DataFrame(data_cos_sim)\n",
        "\n",
        "  def compute_pca_2d(self):\n",
        "      all_embeddings = np.vstack([self.image_embeddings, self.text_embeddings])\n",
        "\n",
        "      pca = PCA(n_components=2)\n",
        "      all_embeddings_2d = pca.fit_transform(all_embeddings)\n",
        "\n",
        "      image_embeddings_2d = all_embeddings_2d[:len(self.image_embeddings)]\n",
        "      text_embeddings_2d = all_embeddings_2d[len(self.image_embeddings):]\n",
        "\n",
        "      data_image_embeddings_2d = {\n",
        "          \"X\": image_embeddings_2d[:, 0],\n",
        "          \"Y\": image_embeddings_2d[:, 1],\n",
        "          \"type\": \"image\"\n",
        "      }\n",
        "\n",
        "      data_text_embeddings_2d = {\n",
        "          \"X\": text_embeddings_2d[:, 0],\n",
        "          \"Y\": text_embeddings_2d[:, 1],\n",
        "          \"type\": \"text\"\n",
        "      }\n",
        "\n",
        "      df_data_image_embeddings_2d = pd.DataFrame(data_image_embeddings_2d)\n",
        "      df_data_text_embeddings_2d = pd.DataFrame(data_text_embeddings_2d)\n",
        "\n",
        "      self.df_embeddings_2d = pd.concat([df_data_image_embeddings_2d, df_data_text_embeddings_2d], ignore_index=True)\n",
        "\n",
        "  def get_pca_2d(self):\n",
        "      if self.df_embeddings_2d is None:\n",
        "          raise Exception(\"[EmbeddingAnalyzer] PCA 2d embedding dataframe is empty. You should execute compute_pca_2d before getting the results.\")\n",
        "\n",
        "      return self.df_embeddings_2d\n",
        "\n",
        "  def get_embeddings_stats(self):\n",
        "      if self.df_stats is None:\n",
        "          raise Exception(\"EmbeddingAnalyzer: Statistics dataframe is empty. You should execute compute_embeddings_stats before getting the results.\")\n",
        "\n",
        "      return self.df_stats\n",
        "\n",
        "  def get_embeddings_cos_sim(self):\n",
        "      if self.df_data_cos_sim is None:\n",
        "          raise Exception(\"EmbeddingAnalyzer: Cosinus similarity dataframe is empty. You should execute compute_embeddings_cos_sim before getting the results.\")\n",
        "\n",
        "      return self.df_data_cos_sim\n",
        "\n",
        "  def save_pca_2d(self, filename = None):\n",
        "      if self.df_embeddings_2d is None:\n",
        "          raise Exception(\"[EmbeddingAnalyzer] PCA 2d embedding dataframe is empty. You should execute compute_pca_2d before saving the results.\")\n",
        "\n",
        "      if filename == None:\n",
        "          filename = f\"{self.model_name}_dataset_{self.dataset_name}_pca_2d.csv\"\n",
        "\n",
        "      if not os.path.exists(self.data_analysis_dir):\n",
        "          os.makedirs(self.data_analysis_dir)\n",
        "\n",
        "      csv_file_save_path = os.path.join(self.data_analysis_dir, filename)\n",
        "      self.df_embeddings_2d.to_csv(csv_file_save_path)\n",
        "\n",
        "  def save_embeddings_stats(self, filename = None):\n",
        "      if self.df_stats is None:\n",
        "          raise Exception(\"[EmbeddingAnalyzer] Statistics dataframe is empty. You should execute compute_embeddings_stats before saving the results.\")\n",
        "\n",
        "      if filename == None:\n",
        "          filename = f\"{self.model_name}_dataset_{self.dataset_name}_embeddings_stats.csv\"\n",
        "\n",
        "      if not os.path.exists(self.data_analysis_dir):\n",
        "          os.makedirs(self.data_analysis_dir)\n",
        "\n",
        "      csv_file_save_path = os.path.join(self.data_analysis_dir, filename)\n",
        "      self.df_stats.to_csv(csv_file_save_path)\n",
        "\n",
        "  def save_embeddings_cos_sim(self, filename = None):\n",
        "      if self.df_data_cos_sim is None:\n",
        "          raise Exception(\"[EmbeddingAnalyzer] Cosinus similarity dataframe is empty. You should execute compute_embeddings_cos_sim before saving the results.\")\n",
        "\n",
        "      if filename == None:\n",
        "          filename = f\"{self.model_name}_dataset_{self.dataset_name}_cos_sim.csv\"\n",
        "\n",
        "      if not os.path.exists(self.data_analysis_dir):\n",
        "          os.makedirs(self.data_analysis_dir)\n",
        "\n",
        "      csv_file_save_path = os.path.join(self.data_analysis_dir, filename)\n",
        "      self.df_data_cos_sim.to_csv(csv_file_save_path)"
      ],
      "metadata": {
        "id": "7L6tfFtY0gW8"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingVisualizer:\n",
        "  def __init__(self,\n",
        "               model_name = \"MODEL\",\n",
        "               dataset_name = \"test\",\n",
        "               data_analysis_dir = \"./data_analysis\",\n",
        "               figures_dir = \"./figures\"):\n",
        "      self.model_name = model_name\n",
        "      self.dataset_name = dataset_name\n",
        "      self.data_analysis_dir = data_analysis_dir\n",
        "      self.figures_dir = figures_dir\n",
        "\n",
        "  def generate_embeddings_plots_with_error_bars(self, df_stats, save=True, show=True):\n",
        "      embed_dim = len(df_stats)\n",
        "\n",
        "      x = np.arange(0, embed_dim)\n",
        "\n",
        "      # Mean text / image vectors with error bars\n",
        "\n",
        "      plt.figure(figsize=(12,5))\n",
        "      plt.errorbar(x, df_stats[\"mean_text_vector\"], df_stats[\"std_text_vector\"], label='Mean text vector', fmt='o')\n",
        "      plt.errorbar(x, df_stats[\"mean_image_vector\"], df_stats[\"std_image_vector\"], label='Mean image vector', fmt='o')\n",
        "      plt.legend()\n",
        "\n",
        "      if save:\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_mean_embeddings_vector.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "\n",
        "  def generate_embeddings_frequency_histograms(self, df_stats, save=True, show=True):\n",
        "      # Frequency histograms\n",
        "      plt.hist(df_stats[\"mean_text_vector\"], bins=30, color='blue', alpha=0.7)\n",
        "\n",
        "      plt.xlabel(\"Value of coordinate\")\n",
        "      plt.ylabel(\"Frequency\")\n",
        "      plt.title(\"Histogram of values of coordinates of text latent vector\")\n",
        "\n",
        "      if save:\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_hist_mean_text_vector.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "\n",
        "      plt.hist(df_stats[\"mean_image_vector\"], bins=30, color='red', alpha=0.7)\n",
        "\n",
        "      plt.xlabel(\"Value of coordinate\")\n",
        "      plt.ylabel(\"Frequency\")\n",
        "      plt.title(\"Histogram of values of coordinates of image latent vector\")\n",
        "\n",
        "      if save:\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_hist_mean_image_vector.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "\n",
        "  def generate_embeddings_plots(self, df_stats, save=True, show=True):\n",
        "      embed_dim = len(df_stats)\n",
        "\n",
        "      x = np.arange(0, embed_dim)\n",
        "      # Min / mean / max image vectors scatter plot\n",
        "\n",
        "      plt.figure(figsize=(12,5))\n",
        "      plt.scatter(x, df_stats[\"mean_image_vector\"], label='Mean image vector', color='blue')\n",
        "      plt.scatter(x, df_stats[\"min_image_vector\"], label='Min image vector', color='green')\n",
        "      plt.scatter(x, df_stats[\"max_image_vector\"], label='Max image vector', color='red')\n",
        "\n",
        "      plt.xlabel(\"Coordinate of latent vector\")\n",
        "      plt.ylabel(\"Value\")\n",
        "      plt.title(\"Image latent vector embeddings\")\n",
        "\n",
        "      plt.legend()\n",
        "\n",
        "      if not os.path.exists(self.figures_dir):\n",
        "          os.makedirs(self.figures_dir)\n",
        "\n",
        "      if save:\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_scatter_image_vector.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "\n",
        "      # Min / mean / max text vectors scatter plot\n",
        "\n",
        "      plt.figure(figsize=(12,5))\n",
        "      plt.scatter(x, df_stats[\"mean_text_vector\"], label='Mean text vector', color='blue')\n",
        "      plt.scatter(x, df_stats[\"min_text_vector\"], label='Min text vector', color='green')\n",
        "      plt.scatter(x, df_stats[\"max_text_vector\"], label='Max text vector', color='red')\n",
        "\n",
        "      plt.xlabel(\"Coordinate of latent vector\")\n",
        "      plt.ylabel(\"Value\")\n",
        "      plt.title(\"Text latent vector embeddings\")\n",
        "\n",
        "      plt.legend()\n",
        "\n",
        "      if save:\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_scatter_text_vector.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "\n",
        "  def generate_embeddings_cos_sim_plots(self, df_data_cos_sim, save=True, show=True):\n",
        "      number_of_samples = len(df_data_cos_sim)\n",
        "\n",
        "      x = np.arange(0, number_of_samples)\n",
        "\n",
        "      plt.figure(figsize=(12,5))\n",
        "      plt.scatter(x, df_data_cos_sim[\"cos_sim\"])\n",
        "\n",
        "      plt.xlabel(\"Sample\")\n",
        "      plt.ylabel(\"Cos similarity value\")\n",
        "      plt.title(\"Cosinus similarity\")\n",
        "\n",
        "      if save:\n",
        "          if not os.path.exists(self.figures_dir):\n",
        "              os.makedirs(self.figures_dir)\n",
        "\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_cos_sim.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "\n",
        "      plt.hist(df_data_cos_sim[\"cos_sim\"], bins=30, color='red', alpha=0.7)\n",
        "\n",
        "      plt.xlabel(\"Cosinus similarity value\")\n",
        "      plt.ylabel(\"Frequency\")\n",
        "      plt.title(\"Distribution of cosinus similarity value\")\n",
        "\n",
        "      if save:\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_hist_cos_sim.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()\n",
        "\n",
        "  def generate_pca_2d_plot(self, df_embeddings_2d, save=True, show=True):\n",
        "      plt.figure(figsize=(8,6))\n",
        "      for t, color, marker in zip(['image', 'text'], ['red', 'blue'], ['o', '^']):\n",
        "          subset = df_embeddings_2d[df_embeddings_2d['type'] == t]\n",
        "          plt.scatter(subset['X'], subset['Y'], c=color, label=t, marker=marker, s=100)\n",
        "\n",
        "      plt.xlabel('X')\n",
        "      plt.ylabel('Y')\n",
        "      plt.title('PCA of Text and Image Vectors')\n",
        "      plt.legend()\n",
        "\n",
        "      if save:\n",
        "          fig_path = os.path.join(self.figures_dir, f\"{self.model_name}_dataset_{self.dataset_name}_plot_pca2d.png\")\n",
        "          plt.savefig(fig_path)\n",
        "\n",
        "      if show:\n",
        "          plt.show()\n",
        "      else:\n",
        "          plt.close()"
      ],
      "metadata": {
        "id": "xZf5rTb27Hc9"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and analyze"
      ],
      "metadata": {
        "id": "vaGU4pbXi2Dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_models_names = {\"INITIAL\": \"clip_pipeline_model_big_dataset_betterCNN_data_augmentation_bs64_val_loss_patience5_epoch30_latent128_textDrop0.2_3ConvLayer_lessAugmentation_dropoutTransformer_0.2&_lerningrate2-4_temp0.14_50_epochs\"}"
      ],
      "metadata": {
        "id": "FXnsCiAEiy3x"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_analysis(model_name, quiet=False):\n",
        "    # 0. Load\n",
        "    if not quiet:\n",
        "        print(\"Loading...\")\n",
        "\n",
        "    model_path = os.path.join(param_dict[\"model_dir\"], f\"{model_name}.keras\")\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # 1. Extract\n",
        "    if not quiet:\n",
        "        print(\"Extracting...\")\n",
        "\n",
        "    extractor = EmbeddingExtractor(\n",
        "        model=model,\n",
        "        model_name=model_name,\n",
        "        data_directory=param_dict['test_dir'],\n",
        "        vocab_path=param_dict['vocab_path'],\n",
        "        vocab_size=param_dict['vocab_size'],\n",
        "        output_sequence_length=param_dict['sequence_length']\n",
        "    )\n",
        "\n",
        "    extractor.compute_embeddings()\n",
        "    image_embeddings, text_embeddings = extractor.get_embeddings()\n",
        "\n",
        "    # 2. Analyze & Export\n",
        "    if not quiet:\n",
        "        print(\"Analyzing...\")\n",
        "\n",
        "    analyzer = EmbeddingAnalyzer(\n",
        "        image_embeddings, text_embeddings,\n",
        "        model_name=model_name,\n",
        "        dataset_name=\"test\",\n",
        "        data_analysis_dir=data_analysis_dir)\n",
        "\n",
        "    analyzer.compute_all()\n",
        "    analyzer.save_embeddings_stats()\n",
        "    analyzer.save_embeddings_cos_sim()\n",
        "    analyzer.save_pca_2d()\n",
        "\n",
        "    # 3. Visualize\n",
        "    if not quiet:\n",
        "        print(\"Visualizing...\")\n",
        "\n",
        "    visualizer = EmbeddingVisualizer(\n",
        "        model_name = \"MODEL\",\n",
        "        dataset_name = \"test\",\n",
        "        data_analysis_dir = data_analysis_dir,\n",
        "        figures_dir = param_dict[\"figures_dir\"]\n",
        "    )\n",
        "\n",
        "    visualizer.generate_embeddings_plots(analyzer.get_embeddings_stats(), show=(not quiet))\n",
        "    visualizer.generate_embeddings_cos_sim_plots(analyzer.get_embeddings_cos_sim(), show=(not quiet))\n",
        "    visualizer.generate_embeddings_frequency_histograms(analyzer.get_embeddings_stats(), show=(not quiet))\n",
        "    visualizer.generate_pca_2d_plot(analyzer.get_pca_2d(), show=(not quiet))\n",
        "\n",
        "    if not quiet:\n",
        "        print(\"Done!\")"
      ],
      "metadata": {
        "id": "39oMXRTHFavv"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_analysis_on_models(models_names, quiet=True):\n",
        "  for model_name in models_names:\n",
        "    run_full_analysis(model_name, quiet=quiet)"
      ],
      "metadata": {
        "id": "7mPtKfkYGr5y"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_full_analysis_on_models(list(analysis_models_names.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewVtbN2AF812",
        "outputId": "590eaf01-07f4-47d5-80a1-7181d56b29c4"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'masked_mean_5' (of type MaskedMean) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_bTMV-gC8Gp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}